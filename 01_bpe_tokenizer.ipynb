{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT0y7yuoD8zhWFZCjJzPY/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is a tokenizer?\n",
        "\n",
        "A system that converts a text into a sequence of discreet symbols (tokens)\n",
        "\n",
        "\n",
        "Tokenizer usually includes the following steps\n",
        "- text normalization / clean up\n",
        "- token splitting (rules on how text is split)\n",
        "- vocabulary\n",
        "- encoder (tokens -> integers)\n",
        "- decoder (integers -> tokens)\n",
        "\n",
        "here the implementation is for a BPE Tokenizer.\n",
        "\n",
        "Reference:\n",
        "- https://en.wikipedia.org/wiki/Byte-pair_encoding\n",
        "- https://huggingface.co/learn/llm-course/en/chapter6/5\n",
        "\n"
      ],
      "metadata": {
        "id": "vKf4stN1ZNGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Status](https://img.shields.io/badge/status-dev%20in%20progress-yellow)"
      ],
      "metadata": {
        "id": "VK3r-m9lc0x4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Set up"
      ],
      "metadata": {
        "id": "2I48Zvztaj5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 loading the dataset"
      ],
      "metadata": {
        "id": "pkdPGEMDbxhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt\n",
        "!wget -q https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\n",
        "\n",
        "!wget -q https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz\n",
        "!gunzip -f owt_train.txt.gz\n",
        "!wget -q https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz\n",
        "!gunzip -f owt_valid.txt.gz\n",
        "\n",
        "!ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z_iKnAAZMvV",
        "outputId": "e85721d8-83c5-4053-974b-8b17734eb75c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 14G\n",
            "-rw-r--r-- 1 root root  12G Feb  7 22:11 owt_train.txt\n",
            "-rw-r--r-- 1 root root 277M Feb  7 22:14 owt_valid.txt\n",
            "drwxr-xr-x 1 root root 4.0K Jan 16 14:24 sample_data\n",
            "-rw-r--r-- 1 root root 2.1G Feb  7 22:10 TinyStoriesV2-GPT4-train.txt\n",
            "-rw-r--r-- 1 root root  22M Feb  7 22:10 TinyStoriesV2-GPT4-valid.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 overview of dataset"
      ],
      "metadata": {
        "id": "3EPss19CauXQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cTyvR5eZHE7",
        "outputId": "36ee1482-11f8-4018-ef9a-ea3de5d54b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== TinyStories train ==\n",
            "\n",
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \n",
            "He said, “Wow, that is a really amazing vase! Can I buy it?” \n",
            "The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\n",
            "So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. \n",
            "== TinyStories valid ==\n",
            "u don't have to be scared of the loud dog, I'll protect you\". The mole felt so safe with the little girl. She was very kind and the mole soon came to trust her. He leaned against her and she kept him safe. The mole had found his best friend.\n",
            "<|endoftext|>\n",
            "Once upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\n",
            "Tom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\n",
            "Sam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\n",
            "== OWT train ==\n",
            "What wouldn't you do to save someone you love?\n",
            "\n",
            "When They Come Calling is a modern ghost story, a suspenseful weaving of urban battles, romance, and supernatural intrigue.\n",
            "\n",
            "Anna is a physician from Kansas City. She’s spent her life giving and caring to others while trying to hide how different she is. Anna has lost everyone she’s ever loved: her relationships, her family, and her hope for something more.\n",
            "== OWT valid ==\n",
            "LOUISVILLE, Ky. — A few unflattering reviews are to be expected with any hotel, particularly one whose rates start at $49 per night. But while complaints about shabby rooms and thin towels are common in the industry, ones like these, from TripAdvisor.com, are not: “It is a clean hotel but there are a lot of homeless people there.” “Run far far away!!!!! This is a homeless shelter, not a hotel!” “DO NOT STAY HERE UNLESS YOU ARE HOMELESS… All of the workers are former addicts/homeless people.” Hotel Louisville, 12 stories of brick adorned with a large white cross, is indeed a hotel and event space open to the public. At the same time, it is a transitional-housing facility, substance-abuse recovery center and job-training site owned and operated by Wayside Christian Mission, a nonprofit that shelters and feeds the city’s homeless population. Wayside bought the building at a foreclosure auction in 2009, never intending to rent rooms to the general public. It was simply a place to house the homeless. But as expenses mounted and travelers came through the lobby, remembering what used to be a Holiday Inn and seeking a place to stay, Wayside began to make use of its empty rooms. Four years later, Hotel Louisville is in many ways an improbable success, serving addicts and the homeless while turning a profit from hotel guests and banquets, even during the recession. Perhaps the nation’s only such hybrid, it defies the usual categories — homeless shelter and charity; hotel and for-profit enterprise — and reflects a growing embrace of commerce by social-services groups normally funded by government and foundation grants. Yet Wayside’s pivot from a traditional model of charity toward the seductions of business tells its own complicated tale, showing just how hard it is to do good.\n",
            "\n",
            "Not In My Backyard\n",
            "\n",
            "The lobby of Hotel Louisville Pat McDonogh for Al Jazeera America Every homeless shelter has a NIMBY problem. Try building a new facility or renovating an old one and the neighbors come out of the woodwork to protest each additional bed. But the battle waged against Hotel Louisville was unusual even in the long history of Wayside Christian Mission, founded in 1957. The saga began six years ago, after the group finally raised enough money to replace its worn-out transitional-housing facility for women and kids. Initially, the married couple at Wayside’s helm — Tim Moseley, a bearded, heavyset minister, and his wife, Nina, an attorney with waist-length platinum blonde hair — intended to build on property it already owned along gentrifying Market Street. Real-estate developers with city-hall ties killed the plan, claiming the need for “historic preservation,” and forced Wayside to sell its Market Street building. The Moseleys then tried to buy a former school, but that effort was blocked by irate neighbors and a zoning decision effectively prohibiting new homeless shelters in the city. The ban was later declared unlawful by the federal Department of Housing and Urban Development.\n"
          ]
        }
      ],
      "source": [
        "!echo \"== TinyStories train ==\"; head -n 5 TinyStoriesV2-GPT4-train.txt #head -n 5 --> show me the first 5 lines of\n",
        "!echo \"== TinyStories valid ==\"; head -n 5 TinyStoriesV2-GPT4-valid.txt\n",
        "!echo \"== OWT train ==\"; head -n 5 owt_train.txt\n",
        "!echo \"== OWT valid ==\"; head -n 5 owt_valid.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Training and Validation Files"
      ],
      "metadata": {
        "id": "BNNWaF4BbPTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "train_files = [\n",
        "    \"TinyStoriesV2-GPT4-train.txt\",\n",
        "    \"owt_train.txt\",\n",
        "]\n",
        "\n",
        "valid_files = [\n",
        "    \"TinyStoriesV2-GPT4-valid.txt\",\n",
        "    \"owt_valid.txt\",\n",
        "]\n",
        "\n",
        "# Sanity checks\n",
        "for f in train_files + valid_files:\n",
        "    p = Path(f)\n",
        "    assert p.exists(), f\"Missing file: {f}\"\n",
        "    assert p.stat().st_size > 0, f\"Empty file: {f}\"\n",
        "\n",
        "print(\"All files found and non-empty.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXJzjEPqbuiy",
        "outputId": "3d5a7092-dd46-4722-ff4e-0ce194498fec"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All files found and non-empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Text Normalization"
      ],
      "metadata": {
        "id": "vf_z0z0ljUYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Whitespaces\n",
        "\n",
        "This code reads text line by line and replaces multiple spaces, tabs, or newlines with a single space.\n"
      ],
      "metadata": {
        "id": "memcJUqSmGDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "whitespace_pattern = re.compile(r'\\s+')\n",
        "\n",
        "def stream_line(paths):\n",
        "  for path in paths:\n",
        "    with open(path, 'r') as f:\n",
        "      for line in f:\n",
        "        if line:\n",
        "          line = line.strip()\n",
        "          line = whitespace_pattern.sub(' ', line)\n",
        "          yield line\n"
      ],
      "metadata": {
        "id": "XhRhVOHDjZg3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "stream = stream_line(train_files)\n",
        "for i in range(5):\n",
        "  print(next(stream))"
      ],
      "metadata": {
        "id": "97ObnE87lSke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6d7484-1916-40df-efa0-b32952852325"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!\n",
            "He said, “Wow, that is a really amazing vase! Can I buy it?”\n",
            "The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\n",
            "So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 End of Word\n",
        "Take a word, split it into characters, and append an end-of-word marker."
      ],
      "metadata": {
        "id": "ctkhZnbLmZIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EOW = \"</eow>\"\n",
        "def word_to_symbols(word):\n",
        "    return tuple(word) + (EOW,)\n",
        "\n",
        "print(word_to_symbols(\"hello\"))"
      ],
      "metadata": {
        "id": "Bn-IwZRemco5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896b465c-d869-4c1e-c44b-5c0710bb8dc6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('h', 'e', 'l', 'l', 'o', '</eow>')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. A mechanism to count the frequency of words"
      ],
      "metadata": {
        "id": "C-5Sw7xhCUjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "def build_word_freqs(lines):\n",
        "  freq = Counter()\n",
        "  for line in lines:\n",
        "    for word in line.split(\" \"):\n",
        "      symbols = word_to_symbols(word)\n",
        "      freq[symbols] += 1\n",
        "  return freq"
      ],
      "metadata": {
        "id": "A8pLGlY0CjWm"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "\n",
        "from itertools import islice\n",
        "\n",
        "sample_lines = islice(\n",
        "    stream_line(train_files),\n",
        "    10_000\n",
        ")\n",
        "\n",
        "word_freqs = build_word_freqs(sample_lines)\n",
        "\n",
        "print(\"Unique symbol sequences:\", len(word_freqs))\n",
        "\n",
        "for i, (k, v) in enumerate(word_freqs.items()):\n",
        "    print(k, \"→\", v)\n",
        "    if i == 5:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "_QsaFdldCjFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a32d030-6e97-4bf4-d58e-f5a9d93f2e41"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique symbol sequences: 11421\n",
            "('</eow>',) → 703\n",
            "('O', 'n', 'c', 'e', '</eow>') → 1075\n",
            "('u', 'p', 'o', 'n', '</eow>') → 1030\n",
            "('a', '</eow>') → 9703\n",
            "('t', 'i', 'm', 'e', '</eow>') → 261\n",
            "('t', 'h', 'e', 'r', 'e', '</eow>') → 1205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Counting Adjacent Symbol Pairs"
      ],
      "metadata": {
        "id": "1rHCCJmNKBjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_pair_freqs(word_freqs):\n",
        "    pair_freqs = Counter()\n",
        "\n",
        "    for symbols, freq in word_freqs.items():\n",
        "      for i in range(len(symbols) - 1):\n",
        "        pair = (symbols[i], symbols[i + 1])\n",
        "        pair_freqs[pair] += freq\n",
        "\n",
        "    return pair_freqs"
      ],
      "metadata": {
        "id": "MwTvMtkAKGi1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pair_freqs = get_pair_freqs(word_freqs)\n",
        "\n",
        "print(\"Number of unique symbol pairs:\", len(pair_freqs))\n",
        "pair_freqs.most_common(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3r6xcUYOLfs",
        "outputId": "13f15a64-9533-4498-a150-518ec4b37c8e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique symbol pairs: 951\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('e', '</eow>'), 49328),\n",
              " (('h', 'e'), 40486),\n",
              " (('d', '</eow>'), 37565),\n",
              " (('t', 'h'), 27762),\n",
              " (('.', '</eow>'), 27072),\n",
              " (('t', '</eow>'), 21366),\n",
              " (('a', 'n'), 20944),\n",
              " (('n', 'd'), 20325),\n",
              " (('y', '</eow>'), 19459),\n",
              " (('s', '</eow>'), 18840)]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Mechanism to merge most frequent pair"
      ],
      "metadata": {
        "id": "j2wdE7fHOM4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_pair = pair_freqs.most_common(1)[0][0]\n",
        "best_pair\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfxzkggiOPqf",
        "outputId": "5568a470-bb33-46ef-e61c-b772ff6098a2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('e', '</eow>')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_symbols(symbols, pair):\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(symbols):\n",
        "        # If we see the target pair, merge it\n",
        "        if i < len(symbols) - 1 and symbols[i] == pair[0] and symbols[i+1] == pair[1]:\n",
        "            merged.append(symbols[i] + symbols[i+1])\n",
        "            i += 2\n",
        "        else:\n",
        "            merged.append(symbols[i])\n",
        "            i += 1\n",
        "    return tuple(merged)\n"
      ],
      "metadata": {
        "id": "YzHLQgzTOTFU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Apply merge"
      ],
      "metadata": {
        "id": "VrNE3YeTOhgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_merge(word_freqs, pair):\n",
        "    new_word_freqs = Counter()\n",
        "\n",
        "    for symbols, freq in word_freqs.items():\n",
        "        new_symbols = merge_symbols(symbols, pair)\n",
        "        new_word_freqs[new_symbols] += freq\n",
        "\n",
        "    return new_word_freqs\n"
      ],
      "metadata": {
        "id": "L4vtTe-5Oczu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freqs = apply_merge(word_freqs, best_pair)\n"
      ],
      "metadata": {
        "id": "hUoJdH_YOobj"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (k, v) in enumerate(word_freqs.items()):\n",
        "    print(k, \"→\", v)\n",
        "    if i == 5:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdoZxpE6OqKj",
        "outputId": "3bb42d38-969b-4999-c425-920759be71be"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('</eow>',) → 703\n",
            "('O', 'n', 'c', 'e</eow>') → 1075\n",
            "('u', 'p', 'o', 'n', '</eow>') → 1030\n",
            "('a', '</eow>') → 9703\n",
            "('t', 'i', 'm', 'e</eow>') → 261\n",
            "('t', 'h', 'e', 'r', 'e</eow>') → 1205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Full Merge Tale"
      ],
      "metadata": {
        "id": "8pZnJx1qOyxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bpe(word_freqs, num_merges=100):\n",
        "    merges = []  # list of pairs in the order we merged them\n",
        "\n",
        "    for m in range(num_merges):\n",
        "        pair_freqs = get_pair_freqs(word_freqs)\n",
        "        if not pair_freqs:\n",
        "            break\n",
        "\n",
        "        best_pair, best_count = pair_freqs.most_common(1)[0]\n",
        "        merges.append(best_pair)\n",
        "\n",
        "        word_freqs = apply_merge(word_freqs, best_pair)\n",
        "\n",
        "        # lightweight progress print\n",
        "        if (m + 1) % 10 == 0 or m < 5:\n",
        "            print(f\"merge {m+1:4d}: {best_pair}  count={best_count}\")\n",
        "\n",
        "    return merges, word_freqs\n"
      ],
      "metadata": {
        "id": "qdohKNNcO0bd"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "\n",
        "from itertools import islice\n",
        "sample_lines = islice(stream_line(train_files), 10_000)\n",
        "word_freqs0 = build_word_freqs(sample_lines)\n",
        "\n",
        "merges, word_freqs_trained = train_bpe(word_freqs0, num_merges=50)\n",
        "\n",
        "print(\"Total merges learned:\", len(merges))\n",
        "print(\"First 10 merges:\", merges[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7XWYjm7O6M5",
        "outputId": "47b09580-d316-4c07-b2b4-6a1ce781dbfd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merge    1: ('e', '</eow>')  count=49328\n",
            "merge    2: ('d', '</eow>')  count=37565\n",
            "merge    3: ('t', 'h')  count=27762\n",
            "merge    4: ('.', '</eow>')  count=27072\n",
            "merge    5: ('t', '</eow>')  count=21366\n",
            "merge   10: ('t', 'o')  count=14655\n",
            "merge   20: ('w', 'a')  count=9191\n",
            "merge   30: ('l', 'l')  count=5755\n",
            "merge   40: ('e', '.</eow>')  count=3748\n",
            "merge   50: ('in', 'g</eow>')  count=3386\n",
            "Total merges learned: 50\n",
            "First 10 merges: [('e', '</eow>'), ('d', '</eow>'), ('t', 'h'), ('.', '</eow>'), ('t', '</eow>'), ('a', 'n'), ('y', '</eow>'), ('s', '</eow>'), (',', '</eow>'), ('t', 'o')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Merge Rank Table"
      ],
      "metadata": {
        "id": "ySeqYfGePARr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_ranks = {pair: i for i, pair in enumerate(merges)}\n"
      ],
      "metadata": {
        "id": "P4tC0hF3PEYe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Adjacent Pairs"
      ],
      "metadata": {
        "id": "DMy7aT63PKxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjacent_pairs(symbols):\n",
        "    return {(symbols[i], symbols[i+1]) for i in range(len(symbols) - 1)}\n"
      ],
      "metadata": {
        "id": "DJf_dTAoPLnE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.  BPE - Single word"
      ],
      "metadata": {
        "id": "M2zHndjAPOAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bpe_encode_word(word, merge_ranks, eow=\"</eow>\"):\n",
        "    symbols = tuple(word) + (eow,)\n",
        "\n",
        "    while True:\n",
        "        pairs = adjacent_pairs(symbols)\n",
        "        # find mergeable pairs\n",
        "        mergeable = [p for p in pairs if p in merge_ranks]\n",
        "        if not mergeable:\n",
        "            break\n",
        "\n",
        "        # pick the pair with best (lowest) rank\n",
        "        best = min(mergeable, key=lambda p: merge_ranks[p])\n",
        "        symbols = merge_symbols(symbols, best)\n",
        "\n",
        "    return symbols\n"
      ],
      "metadata": {
        "id": "8qwTPTCUPnFZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bpe_encode_text(text, merge_ranks, lowercase=False):\n",
        "    if lowercase:\n",
        "        text = text.lower()\n",
        "    words = text.strip().split()\n",
        "    out = []\n",
        "    for w in words:\n",
        "        out.extend(bpe_encode_word(w, merge_ranks))\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "XP4FP2xRPuB4"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"Once upon a time there was a cat\",\n",
        "    \"the the the\",\n",
        "    \"there was time\",\n",
        "]\n",
        "\n",
        "for t in tests:\n",
        "    print(\"TEXT:\", t)\n",
        "    print(\"TOKENS:\", bpe_encode_text(t, merge_ranks))\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-aME6g_PxJJ",
        "outputId": "c7b2b629-07ba-46f9-fe88-f440d2d2d07a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT: Once upon a time there was a cat\n",
            "TOKENS: ['O', 'n', 'c', 'e</eow>', 'u', 'p', 'on', '</eow>', 'a</eow>', 't', 'i', 'm', 'e</eow>', 'th', 'er', 'e</eow>', 'was</eow>', 'a</eow>', 'c', 'a', 't</eow>']\n",
            "\n",
            "TEXT: the the the\n",
            "TOKENS: ['the</eow>', 'the</eow>', 'the</eow>']\n",
            "\n",
            "TEXT: there was time\n",
            "TOKENS: ['th', 'er', 'e</eow>', 'was</eow>', 't', 'i', 'm', 'e</eow>']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Vocab building plus, conversion to integer ID"
      ],
      "metadata": {
        "id": "EF7Fh0IwP0ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_token_set(word_freqs):\n",
        "    tokens = set()\n",
        "    for symbols in word_freqs.keys():\n",
        "        for s in symbols:\n",
        "            tokens.add(s)\n",
        "    return tokens\n",
        "\n",
        "tokens = build_token_set(word_freqs_trained)\n",
        "\n",
        "print(\"Number of tokens in vocab (from trained sample):\", len(tokens))\n",
        "print(\"Example tokens:\", list(sorted(tokens))[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFNZUC2PP9Kb",
        "outputId": "a5f490a6-25c2-45de-bc1b-ade58320c4c7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in vocab (from trained sample): 125\n",
            "Example tokens: ['!', '\"', '\"</eow>', \"'\", ',', ',</eow>', '-', '.', '.</eow>', '0', '1', '3', '8', '9', ':', ';', '<', '</eow>', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'The', 'The</eow>', 'They</eow>', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPECIAL_TOKENS = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "for t in SPECIAL_TOKENS:\n",
        "    tokens.add(t)\n"
      ],
      "metadata": {
        "id": "SBLPrs1VP_Y-"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_sorted = sorted(tokens)\n",
        "\n",
        "token_to_id = {t: i for i, t in enumerate(tokens_sorted)}\n",
        "id_to_token = {i: t for t, i in token_to_id.items()}\n",
        "\n",
        "print(\"Vocab size:\", len(token_to_id))\n",
        "print(\"IDs:\", {t: token_to_id[t] for t in SPECIAL_TOKENS})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpKof9rJQBIL",
        "outputId": "6926883d-c713-41fa-9353-0bed7a8c8d49"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 129\n",
            "IDs: {'<pad>': 20, '<unk>': 21, '<bos>': 18, '<eos>': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_ID = token_to_id[\"<unk>\"]\n",
        "\n",
        "def encode_to_ids(text, merge_ranks, token_to_id):\n",
        "    toks = bpe_encode_text(text, merge_ranks)\n",
        "    return [token_to_id.get(tok, UNK_ID) for tok in toks]\n"
      ],
      "metadata": {
        "id": "RtNr1oP-QDDV"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Once upon a time there was a cat\"\n",
        "print(encode_to_ids(s, merge_ranks, token_to_id)[:50])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czFDki9DQFAB",
        "outputId": "09584253-ab06-4c61-c5b1-a2f83110365f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[38, 91, 60, 66, 112, 97, 94, 17, 54, 105, 79, 89, 66, 107, 69, 66, 117, 54, 60, 53, 106]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Save merges in standard “pair per line” format\n",
        "with open(\"merges.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for a, b in merges:\n",
        "        f.write(f\"{a} {b}\\n\")\n",
        "\n",
        "# Save vocab as JSON\n",
        "with open(\"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(token_to_id, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved merges.txt and vocab.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bMS_Ep0QHWB",
        "outputId": "9db0c3da-3764-44c1-e780-35ed46f258ec"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved merges.txt and vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vocab.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "# View first 30 tokens\n",
        "for i, (k, v) in enumerate(vocab.items()):\n",
        "    print(k, \"→\", v)\n",
        "    if i == 100:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcT1zJ6vQLle",
        "outputId": "ae86a35b-4120-4138-c8ae-7ed1a8a374b6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "! → 0\n",
            "\" → 1\n",
            "\"</eow> → 2\n",
            "' → 3\n",
            ", → 4\n",
            ",</eow> → 5\n",
            "- → 6\n",
            ". → 7\n",
            ".</eow> → 8\n",
            "0 → 9\n",
            "1 → 10\n",
            "3 → 11\n",
            "8 → 12\n",
            "9 → 13\n",
            ": → 14\n",
            "; → 15\n",
            "< → 16\n",
            "</eow> → 17\n",
            "<bos> → 18\n",
            "<eos> → 19\n",
            "<pad> → 20\n",
            "<unk> → 21\n",
            "> → 22\n",
            "? → 23\n",
            "A → 24\n",
            "B → 25\n",
            "C → 26\n",
            "D → 27\n",
            "E → 28\n",
            "F → 29\n",
            "G → 30\n",
            "H → 31\n",
            "I → 32\n",
            "J → 33\n",
            "K → 34\n",
            "L → 35\n",
            "M → 36\n",
            "N → 37\n",
            "O → 38\n",
            "P → 39\n",
            "Q → 40\n",
            "R → 41\n",
            "S → 42\n",
            "T → 43\n",
            "The → 44\n",
            "The</eow> → 45\n",
            "They</eow> → 46\n",
            "U → 47\n",
            "V → 48\n",
            "W → 49\n",
            "X → 50\n",
            "Y → 51\n",
            "Z → 52\n",
            "a → 53\n",
            "a</eow> → 54\n",
            "an → 55\n",
            "and</eow> → 56\n",
            "ar → 57\n",
            "b → 58\n",
            "bi → 59\n",
            "c → 60\n",
            "d → 61\n",
            "d</eow> → 62\n",
            "do → 63\n",
            "e → 64\n",
            "e.</eow> → 65\n",
            "e</eow> → 66\n",
            "ed</eow> → 67\n",
            "en → 68\n",
            "er → 69\n",
            "er</eow> → 70\n",
            "f → 71\n",
            "g → 72\n",
            "g</eow> → 73\n",
            "h → 74\n",
            "ha → 75\n",
            "he → 76\n",
            "he</eow> → 77\n",
            "hi → 78\n",
            "i → 79\n",
            "id → 80\n",
            "in → 81\n",
            "ing</eow> → 82\n",
            "j → 83\n",
            "k → 84\n",
            "l → 85\n",
            "la → 86\n",
            "li → 87\n",
            "ll → 88\n",
            "m → 89\n",
            "m</eow> → 90\n",
            "n → 91\n",
            "o → 92\n",
            "om → 93\n",
            "on → 94\n",
            "or → 95\n",
            "ou → 96\n",
            "p → 97\n",
            "q → 98\n",
            "r → 99\n",
            "re → 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Decoder"
      ],
      "metadata": {
        "id": "EqGgjLzvQQ29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_ids(ids, id_to_token, eow=\"</eow>\"):\n",
        "\n",
        "    skip = {\"<pad>\", \"<bos>\", \"<eos>\"}  # keep <unk> visible unless you prefer skipping it\n",
        "\n",
        "    tokens = []\n",
        "    for i in ids:\n",
        "        tok = id_to_token.get(i, \"<unk>\")\n",
        "        if tok in skip:\n",
        "            continue\n",
        "        tokens.append(tok)\n",
        "\n",
        "    # Build text by concatenating pieces; whenever we see eow, we emit a space.\n",
        "    out_chars = []\n",
        "    for tok in tokens:\n",
        "        if tok == eow:\n",
        "            out_chars.append(\" \")\n",
        "            continue\n",
        "\n",
        "        if tok.endswith(eow):\n",
        "            # token like 'e</w>' or 'there</w>'\n",
        "            out_chars.append(tok[: -len(eow)])\n",
        "            out_chars.append(\" \")\n",
        "        else:\n",
        "            out_chars.append(tok)\n",
        "\n",
        "    text = \"\".join(out_chars).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "eHUyjoIWQWk0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Once upon a time there was a cat\"\n",
        "ids = encode_to_ids(s, merge_ranks, token_to_id)\n",
        "print(\"IDS:\", ids[:30])\n",
        "\n",
        "decoded = decode_ids(ids, id_to_token)\n",
        "print(\"DECODED:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUmnr70sQr__",
        "outputId": "110c5167-0f46-466f-cc7d-576793e51ea7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDS: [38, 91, 60, 66, 112, 97, 94, 17, 54, 105, 79, 89, 66, 107, 69, 66, 117, 54, 60, 53, 106]\n",
            "DECODED: Once upon a time there was a cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "OZRvkeDqbfA6"
      }
    }
  ]
}